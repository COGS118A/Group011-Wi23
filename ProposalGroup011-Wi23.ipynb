{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Joshua Howon Kim \n",
    "- Yewon Hong\n",
    "- Seonghun Oh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The goal of our project is to classify if a news is fake or not. The data we are using is scraped from snopes.com which is a website that fact checks and analyzes information from the news. The variables in the dataset include: the title, comments by the public on the fact, claims to support the comment, label of the news(True, False, Miscaptioned), summary of the content, information that are true, false and unknown. We will be using these data to understand how each variable affects on the validity of the news content. In order to validate if the news is fake or not, we will be using multivariable logistic regression.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "As SNS spreads rapidly, fake news disguised as the media remains a major social problem. Fake news has become a particular public issue for the following reason:As online public opinion spheres are activated, people have diverse and easy access to platforms such as YouTube, and SNS. Unverified issues are produced and spread easily in that they can be freely spoken and shared information and opinions, making it easy for anyone to make news that may be extreme or wrongful, and spread them. Since 2017, academic research and discussion have gotten in earnest in the United States, where fake news remarked by Trump had been shifted to fake news.[<sup>1</sup>](#fn1)",
    "According to previous discussions of fake news, fake news has been broadly defined as A) for political and economic gain, B) deliberately distorting and fabricating, and C) false information disguised as media coverage. [<sup>2</sup>](#fn2)",
    "With the introduction of artificial intelligence and various technology to distinguish fake news and unidentified information by SNS, media companies, also with the emergence of several fact-checking media show that media literacy has become a must for modern people. [<sup>3</sup>](#fn3)"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Fake news damages certain people's reputation, violates someone’s privacy and personality rights and causes false prejudices against specific groups. Furthermore, it reduces the credibility of established media and other opinions and causes distortions in the process of forming political opinions. This causes social confusion and division, which harms civil society and its members and society as a whole. This is because it can cover facts and truths and spread false or distorted information to hinder the formation of sound public opinion. Naturally, such crackdowns and regulations on fake news are necessary. However, the biggest problem with fake news that we faced is that the current concept of fake news can be widespread and ambiguous. This is why the priority should be to find out what fake news is if legislation is to save damage to fake news. In a world of millions of news, they rely on manual human detection, so their scope is so limited that if the fake news is posted and deleted every minute, they cannot be manually responsible or executed. It can be a solution through the development of a system that provides reliable, automated exponential scores, namely trained machine learning.  solution through the development of a system that provides reliable, automated exponential scores, namely trained machine learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Question: News/Fact's title\n",
    "\n",
    "Comment: A short comment by the public on the fact\n",
    "\n",
    "Claim: Claim to support the comment\n",
    "Rate: label of the news(True, False, Miscaptioned etc.)\n",
    "\n",
    "Origin: Content of the page\n",
    "\n",
    "summary: Short Version of origin feature\n",
    "\n",
    "\n",
    "Label dependent features:\n",
    "What's True: True about the fact\n",
    "What's False: False about the fact\n",
    "What's Unknown: What's Unknown about the fact\n",
    "\n",
    "We propose a methodology that applies supervised machine learning algorithms to a label dependent features dataset to create a model that detects whether an article is true or fake based on Question, Comment, Claim, Rate, and summary features. Also, we found the other dataset deals with:Post number, article unique number, title, article title, URL, article link, summary, article summary, article publication date, article publication date, revision date, category, category of  fake news subject, Claim, Veracity (Evaluation result of verified rumor. True, can have values such as most true, most false, etc.), source of information (the source of information used to verify the fake news), It was confirmed that there is a Snopes dataset with a total of 16 features. We can obtain useful information from this dataset via Claim and Veracity."







    
    
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Solution: multivariable logistic regression\n",
    "\n",
    "Library used: numpy, pandas, scikit-learn\n",
    "\n",
    "Since our problem is a binary classification of evaluating if the news is true or false, we will be using logistic regression. In order to process the test into input data, we will be using vectorization. Then we will be adding this vectorized input to variables from multiple columns and evaluate whether the news is true or false. Thus, we will be using multivariable logistic regression. First of all, we will be dividing the dataset into training/validation set and test set. Next, because vectorizing the text into word units creates too many variables, we will be using normalization. Because we will be needing strong normalization, we believe that using L1 normalization will be effective. The search plane itself is a vectorized text, therefore it is possible for it to become very high dimension which may result in being stuck in the local minima. In order to prevent this problem, we will be using momentum in our training. Also, in order to quickly do weight updates in training, we will be using mini-batch. In the validation step, we will be using K-fold cross validation to retreive the most accurate model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "The evaluation metrics we will be using will be True positive rate (recall) and Accuracy. For recall, we will be using (correctly evaluating that news is false) / (correctly evaluating that news is false + evaluating that news is true when it is actually false). This recall rate is important for our problem because it tells us the rate of us being able to correctly evaluate that the news is false. For Accuracy, we will be using (correctly evaluating that news is false + evaluating that news is false when it is actually true) / (correctly evaluating that news is false + correctly evaluating that news is true + evaluating that news is true when it is actually false + evaluating that news is false when it is actually true). Accuracy is important for our problem because it tells us if our model was able to accurately make correct predictions in evaluating that the news is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "In our dataset, there may be some potential ethical concerns because we are retrieving our data from previously published news articles. Because we are basically evaluating whether a person’s article is true or false, in some way, we are criticizing the person’s work. Therefore, by providing data that a person’s work is wrong, it may harm the person’s career. We also think that this may also bring up privacy issues because we are using someone else’s work and evaluating it without the publisher’s permission. However, we believe that this will not be that much of a problem because news itself will always be biased in some sort of way and it is the reader’s responsibility to take in only correct information. Therefore, we believe that our project serves a good purpose because it helps the reader’s to make correct decisions in trusting the correct news article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Contact over group chat*\n",
    "* *Respond as quickly as possible within 24 hours*\n",
    "* *Meetings will happen at least once a week and all members have to attend*\n",
    "* *All members are expected and responsible for finishing their divided work*\n",
    "* *All members should review other's work and provide feedback*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Agenda  | Finish by next meeting |\n",
    "|---|---|---|---|\n",
    "| 2/20  |  4 PM |  Discuss about proposal  | Finish each assigned part of proposal | \n",
    "| 2/22  |  4 PM |  Peer review and finalize proposal and turn it in; start basic research | add research to the shared google doc | \n",
    "| 2/27  | 4 PM  |  Discuss EDA progress and brainstorm together | Continue making progress and each person should write their assigned portions code |\n",
    "| 3/3  | 4 PM  | Discuss entire project and go through everything | Prepare exploratory data analysis |\n",
    "| 3/7  | 4 PM  | Go over everything one more time and turn in group CheckPoint | Discuss/edit project code |\n",
    "| 3/13 | 4 PM | Discuss each persons progress and give feedback | Complete analysis and start conclusion and report |\n",
    "| 3/17  | 4 PM  | Go over everyone's progress and Finalize project | Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^]The Media's Definition of Fake News vs. Donald Trump's. https://scholarship.law.unc.edu/cgi/viewcontent.cgi?article=1244&amp;context=falr. <br> \n",
    "<a name=\"admonishnote\"></a>2.[^]West, Darrell M. “How to Combat Fake News and Disinformation.” Brookings, Brookings, 9 Mar. 2022, https://www.brookings.edu/research/how-to-combat-fake-news-and-disinformation/. <br>\n",
    "<a name=\"sotanote\"></a>3.[^]https://arxiv.org/pdf/2102.04458.pdf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
